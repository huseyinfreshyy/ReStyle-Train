{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPI5E5y0pujD"
      },
      "source": [
        "# Custom Training ReStyle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51ei6d5kxVDm"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YcUMPQp6ipP"
      },
      "source": [
        "## Install Repo to Google Drive\n",
        "\n",
        "Colab is a little funky with training. I’ve found the best way to do this is to install the repo directly into your Google Drive folder.\n",
        "\n",
        "First, mount your Drive to the Colab notebook: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxxYlEKI9Gis"
      },
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'restyle-encoder'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epV6TDzAjox1"
      },
      "source": [
        "Next, run this cell. If you’re already installed the repo, it will skip the installation process and change into the repo’s directory. If you haven’t installed it, it will install all the files necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HX77jscX2zV"
      },
      "source": [
        "!git clone https://github.com/yuval-alaluf/restyle-encoder.git $CODE_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7oj_kBaemol"
      },
      "source": [
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(f'./{CODE_DIR}')"
      ],
      "metadata": {
        "id": "Ww6meEOp5sLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import pprint\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp\n",
        "from models.e4e import e4e\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "WAARRkxF43En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_type = 'my_data_encode'"
      ],
      "metadata": {
        "id": "LWArNpvbG065"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_download_model_command(file_id, file_name):\n",
        "    \"\"\" Get wget download command for downloading the desired model and save to directory ../pretrained_models. \"\"\"\n",
        "    current_directory = os.getcwd()\n",
        "    save_path = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"pretrained_models\")\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
        "    return url    "
      ],
      "metadata": {
        "id": "k4__uxeQG6KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATHS = {\n",
        "    \"my_data_encode\": {\"id\": \"1sw6I2lRIB0MpuJkpc8F5BJiSZrc0hjfE\", \"name\": \"restyle_psp_ffhq_encode.pt\"},\n",
        "}\n",
        "\n",
        "path = MODEL_PATHS[experiment_type]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"]) "
      ],
      "metadata": {
        "id": "Mv91jwgLGxuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeS9tDvt61VG"
      },
      "source": [
        "## Convert dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q58MJbckLUc"
      },
      "source": [
        "**Note: You only need to do this once per dataset. If you have already run this and are returning to conntinue training, skip these cells.**\n",
        "\n",
        "Next we need to convert our image dataset to a format that StyleGAN2-ADA can read from. There are two options here. You can upload your dataset directly to Colab (as a zipped file), or you can upload it to Drive directly and read it from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JUP51nJdEjz"
      },
      "source": [
        "dataset_paths = {\n",
        "\t'train_data': '/content/drive/MyDrive/colab-sg2-ada/face_datasets',\n",
        "  'test_data': '/content/face_test_data'\n",
        "}\n",
        "\n",
        "\n",
        "DATASETS = {\n",
        "\t'my_data_encode': {\n",
        "\t\t'transforms': transforms_config.EncodeTransforms,   # can define a custom transform, if desired\n",
        "\t\t'train_source_root': dataset_paths['train_data'],\n",
        "\t\t'train_target_root': dataset_paths['train_data'],\n",
        "\t\t'test_source_root': dataset_paths['test_data'],\n",
        "\t\t'test_target_root': dataset_paths['test_data'],\n",
        "\t}\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "btLe5agg8z9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0QH0nzjlbEE"
      },
      "source": [
        "Now that your image dataset is uploaded, we need to convert it to the `.tfrecords` format.\n",
        "\n",
        "Depending on the resolution of your images and how many you have, this can take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-BZHhBe7AvO"
      },
      "source": [
        "!python scripts/train_restyle_psp.py \\\n",
        "--dataset_type my_data_encode \\\n",
        "--encoder_type=BackboneEncoder \\\n",
        "--exp_dir=experiment/restyle_psp_ffhq_encode \\\n",
        "--workers=8 \\\n",
        "--batch_size=8 \\\n",
        "--test_batch_size=8 \\\n",
        "--test_workers=8 \\\n",
        "--val_interval=5000 \\\n",
        "--save_interval=10000 \\\n",
        "--start_from_latent_avg \\\n",
        "--lpips_lambda=0.8 \\\n",
        "--l2_lambda=1 \\\n",
        "--w_norm_lambda=0 \\\n",
        "--id_lambda=0.1 \\\n",
        "--input_nc=6 \\\n",
        "--n_iters_per_batch=5 \\\n",
        "--output_size=1024 \\\n",
        "--stylegan_weights=pretrained_models/restyle_psp_ffhq_encode.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/train_restyle_e4e.py \\\n",
        "--dataset_type my_data_encode \\\n",
        "--encoder_type ProgressiveBackboneEncoder \\\n",
        "--exp_dir=experiment/restyle_e4e_ffhq_encode \\\n",
        "--workers=8 \\\n",
        "--batch_size=8 \\\n",
        "--test_batch_size=8 \\\n",
        "--test_workers=8 \\\n",
        "--start_from_latent_avg \\\n",
        "--lpips_lambda=0.8 \\\n",
        "--l2_lambda=1 \\\n",
        "--delta_norm_lambda 0.0002 \\\n",
        "--id_lambda 0.1 \\\n",
        "--use_w_pool \\\n",
        "--w_discriminator_lambda 0.1 \\\n",
        "--progressive_start 20000 \\\n",
        "--progressive_step_every 2000 \\\n",
        "--input_nc 6 \\\n",
        "--n_iters_per_batch=5 \\\n",
        "--output_size 1024 \\\n",
        "--stylegan_weights=pretrained_models/restyle_psp_ffhq_encode.pt"
      ],
      "metadata": {
        "id": "hYRpxAu_-vQv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}